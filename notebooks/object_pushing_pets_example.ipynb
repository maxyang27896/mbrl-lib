{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import gym\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, shutil\n",
    "import torch\n",
    "import omegaconf\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import mbrl.env.cartpole_continuous as cartpole_env\n",
    "import mbrl.env.reward_fns as reward_fns\n",
    "import mbrl.env.termination_fns as termination_fns\n",
    "import mbrl.models as models\n",
    "import mbrl.planning as planning\n",
    "import mbrl.util.common as common_util\n",
    "import mbrl.util as util\n",
    "from mbrl.util.math import euler_to_quaternion, quaternion_rotation_matrix\n",
    "\n",
    "import tactile_gym.rl_envs\n",
    "from tactile_gym.sb3_helpers.params import import_parameters\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "mpl.rcParams.update({\"font.size\": 16})\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce a display to render image\n",
    "from pyvirtualdisplay import Display\n",
    "_display = Display(visible=False, size=(1400, 900))\n",
    "_ = _display.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Training Environment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo_name': 'ppo', 'env_name': 'object_push-v0', 'max_ep_len': 2000, 'image_size': [128, 128], 'env_modes': {'movement_mode': 'TyRz', 'control_mode': 'TCP_position_control', 'rand_init_orn': False, 'rand_obj_mass': False, 'traj_type': 'point', 'observation_mode': 'tactile_pose_goal_excluded_data', 'reward_mode': 'dense', 'terminate_early': True, 'use_contact': True, 'task': 'goal_pos', 'additional_reward_settings': 'guide_off', 'mpc_goal_orn_update': True, 'planar_states': True, 'tcp_lims': [[-0.3, 0.3], [-0.3, 0.3], [-0.0, 0.0], [-0.0, 0.0], [-0.0, 0.0], [-3.141592653589793, 3.141592653589793]], 'goal_edges': ((0, -1), (0, 1), (1, 0)), 'goal_ranges': [-0.18, 0.18, -0.18, 0.18]}, 'policy': 'MultiInputPolicy', 'seed': 1, 'n_stack': 1, 'total_timesteps': 1000000, 'n_eval_episodes': 10, 'n_envs': 10, 'eval_freq': 2000.0}\n",
      "{'policy_kwargs': {'features_extractor_class': <class 'tactile_gym.sb3_helpers.custom.custom_torch_layers.CustomCombinedExtractor'>, 'features_extractor_kwargs': {'cnn_base': <class 'stable_baselines3.common.torch_layers.NatureCNN'>, 'cnn_output_dim': 256, 'mlp_extractor_net_arch': [64, 64]}, 'net_arch': [{'pi': [256, 256], 'vf': [256, 256]}], 'activation_fn': <class 'torch.nn.modules.activation.Tanh'>}, 'learning_rate': 0.0003, 'n_steps': 2048, 'batch_size': 64, 'n_epochs': 10, 'gamma': 0.95, 'gae_lambda': 0.9, 'clip_range': 0.2, 'clip_range_vf': None, 'ent_coef': 0.0, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'use_sde': False, 'sde_sample_freq': -1, 'target_kl': 0.1}\n",
      "argv[0]=\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Mar  8 2021 17:26:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded EGL 1.5 after reload.\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA GeForce RTX 3090/PCIe/SSE2\n",
      "GL_VERSION=4.6.0 NVIDIA 495.29.05\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60 NVIDIA\n",
      "Version = 4.6.0 NVIDIA 495.29.05\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA GeForce RTX 3090/PCIe/SSE2\n",
      "ven = NVIDIA Corporation\n",
      "ven = NVIDIA Corporation\n"
     ]
    }
   ],
   "source": [
    "# Make the pushing environment\n",
    "algo_name = 'ppo'\n",
    "env_name = 'object_push-v0'\n",
    "rl_params, algo_params, augmentations = import_parameters(env_name, algo_name)\n",
    "rl_params[\"env_modes\"][ 'observation_mode'] = 'tactile_pose_goal_excluded_data'\n",
    "rl_params[\"env_modes\"][ 'control_mode'] = 'TCP_position_control'\n",
    "# rl_params[\"env_modes\"]['movement_mode'] = 'TxTyRz'\n",
    "rl_params[\"max_ep_len\"] = 2000\n",
    "rl_params[\"env_modes\"][ 'terminate_early']  = True\n",
    "rl_params[\"env_modes\"][ 'use_contact'] = True\n",
    "rl_params[\"env_modes\"][ 'traj_type'] = 'point'\n",
    "rl_params[\"env_modes\"][ 'task'] = \"goal_pos\"\n",
    "rl_params[\"env_modes\"]['additional_reward_settings'] = 'guide_off'\n",
    "rl_params[\"env_modes\"]['mpc_goal_orn_update'] = True\n",
    "rl_params[\"env_modes\"]['planar_states'] = True\n",
    "\n",
    "# set limits and goals\n",
    "TCP_lims = np.zeros(shape=(6, 2))\n",
    "TCP_lims[0, 0], TCP_lims[0, 1] = -0.3, 0.3  # x lims\n",
    "TCP_lims[1, 0], TCP_lims[1, 1] = -0.3, 0.3  # y lims\n",
    "TCP_lims[2, 0], TCP_lims[2, 1] = -0.0, 0.0  # z lims\n",
    "TCP_lims[3, 0], TCP_lims[3, 1] = -0.0, 0.0  # roll lims\n",
    "TCP_lims[4, 0], TCP_lims[4, 1] = -0.0, 0.0  # pitch lims\n",
    "TCP_lims[5, 0], TCP_lims[5, 1] = -180 * np.pi / 180, 180 * np.pi / 180  # yaw lims\n",
    "\n",
    "# goal parameter\n",
    "goal_edges = ((0, -1), (0, 1), (1, 0))\n",
    "goal_x_max = np.float64(TCP_lims[0, 1] * 0.6).item()\n",
    "goal_x_min = np.float64(TCP_lims[0, 0] * 0.6).item()\n",
    "goal_y_max = np.float64(TCP_lims[1, 1] * 0.6).item()\n",
    "goal_y_min = np.float64(TCP_lims[1, 0] * 0.6).item()\n",
    "goal_ranges = [goal_x_min, goal_x_max, goal_y_min, goal_y_max]\n",
    "\n",
    "rl_params[\"env_modes\"]['tcp_lims'] = TCP_lims.tolist()\n",
    "rl_params[\"env_modes\"]['goal_edges'] = ((0, -1), (0, 1), (1, 0))\n",
    "rl_params[\"env_modes\"]['goal_ranges'] = goal_ranges\n",
    "\n",
    "print(rl_params)\n",
    "print(algo_params)\n",
    "\n",
    "env_kwargs={\n",
    "    'show_gui':False,\n",
    "    'show_tactile':False,\n",
    "    'max_steps':rl_params[\"max_ep_len\"],\n",
    "    'image_size':rl_params[\"image_size\"],\n",
    "    'env_modes':rl_params[\"env_modes\"],\n",
    "}\n",
    "env = gym.make(env_name, **env_kwargs)\n",
    "\n",
    "seed = 0\n",
    "env.seed(seed)\n",
    "rng = np.random.default_rng(seed=0)\n",
    "generator = torch.Generator(device=device)\n",
    "generator.manual_seed(seed)\n",
    "obs_shape = env.observation_space.shape\n",
    "act_shape = env.action_space.shape\n",
    "\n",
    "# This functions allows the model to evaluate the true rewards given an observation \n",
    "reward_fn = reward_fns.cartpole\n",
    "# This function allows the model to know if an observation should make the episode end\n",
    "term_fn = termination_fns.cartpole\n",
    "\n",
    "# Define model working directorys\n",
    "work_dir = os.path.join(os.getcwd(), 'saved_model')\n",
    "# work_dir = os.path.join(os.getcwd(), 'training_cfg')\n",
    "if not os.path.exists(work_dir):\n",
    "    os.mkdir(work_dir)\n",
    "else:\n",
    "    for filename in os.listdir(work_dir):\n",
    "        file_path = os.path.join(work_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000937 0.000079 0.000006 1.000000 -0.001000 0.000000 0.000000 1.000000]\n",
      "[0.000937 0.000079 0.000006 1.000000 -0.001000 0.000000 0.000000 1.000000]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(env.reset())\n",
    "print(env.get_observation())\n",
    "print(type(env.get_observation()))\n",
    "# print(env.get_tactile_pose_obs_goal_exluded())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(8,)\n",
      "Box(2,)\n",
      "(8,)\n",
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)\n",
    "print(obs_shape)\n",
    "print(act_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_length = env._max_steps\n",
    "num_trials = 1\n",
    "ensemble_size = 5\n",
    "initial_buffer_size = 2000\n",
    "buffer_size = num_trials * trial_length\n",
    "target_normalised = True\n",
    "\n",
    "# Everything with \"???\" indicates an option with a missing value.\n",
    "# Our utility functions will fill in these details using the \n",
    "# environment information\n",
    "cfg_dict = {\n",
    "    # dynamics model configuration\n",
    "    \"dynamics_model\": {\n",
    "        \"_target_\": \"mbrl.models.GaussianMLP\",\n",
    "        \"device\": device,\n",
    "        \"num_layers\": 3,\n",
    "        \"ensemble_size\": ensemble_size,\n",
    "        \"hid_size\": 200,\n",
    "        \"in_size\": \"???\",\n",
    "        \"out_size\": \"???\",\n",
    "        \"deterministic\": False,\n",
    "        \"propagation_method\": \"fixed_model\",\n",
    "        # can also configure activation function for GaussianMLP\n",
    "        \"activation_fn_cfg\": {\n",
    "            \"_target_\": \"torch.nn.LeakyReLU\",\n",
    "            \"negative_slope\": 0.01\n",
    "        }\n",
    "    },\n",
    "    # options for training the dynamics model\n",
    "    \"algorithm\": {\n",
    "        \"learned_rewards\": False,\n",
    "        \"target_is_delta\": True,\n",
    "        \"normalize\": True,\n",
    "        \"target_normalize\": target_normalised,\n",
    "        \"dataset_size\": buffer_size\n",
    "    },\n",
    "    # these are experiment specific options\n",
    "    \"overrides\": {\n",
    "        \"trial_length\": trial_length,\n",
    "        \"num_steps\": num_trials * trial_length,\n",
    "        \"model_batch_size\": 32,\n",
    "        \"validation_ratio\": 0.05\n",
    "    }\n",
    "}\n",
    "cfg = omegaconf.OmegaConf.create(cfg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qt21590/anaconda3/envs/tactile_gym_mbrl/lib/python3.9/site-packages/hydra/utils.py:32: UserWarning: `OmegaConf.is_none()` is deprecated, see https://github.com/omry/omegaconf/issues/547\n",
      "  if OmegaConf.is_none(config):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneDTransitionRewardModel(\n",
      "  (model): GaussianMLP(\n",
      "    (hidden_layers): Sequential(\n",
      "      (0): Sequential(\n",
      "        (0): EnsembleLinearLayer(num_members=5, in_size=10, out_size=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): EnsembleLinearLayer(num_members=5, in_size=200, out_size=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): EnsembleLinearLayer(num_members=5, in_size=200, out_size=200, bias=True)\n",
      "        (1): LeakyReLU(negative_slope=0.01)\n",
      "      )\n",
      "    )\n",
      "    (mean_and_logvar): EnsembleLinearLayer(num_members=5, in_size=200, out_size=16, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "\n",
    "# Create a gym-like environment to encapsulate the model\n",
    "model_env = models.ModelEnvPushing(env, dynamics_model, termination_fn=None, reward_fn=None, generator=generator)\n",
    "\n",
    "print(dynamics_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# samples stored 2000\n"
     ]
    }
   ],
   "source": [
    "replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)\n",
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    initial_buffer_size, # initial exploration steps\n",
    "    planning.RandomAgent(env),\n",
    "    {}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=replay_buffer,\n",
    "    trial_length=trial_length\n",
    ")\n",
    "\n",
    "print(\"# samples stored\", replay_buffer.num_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_type = \"icem\"\n",
    "\n",
    "if optimizer_type == \"cem\":\n",
    "    optimizer_cfg = {\n",
    "            \"_target_\": \"mbrl.planning.CEMOptimizer\",\n",
    "            \"num_iterations\": 5,\n",
    "            \"elite_ratio\": 0.1,\n",
    "            \"population_size\": 500,\n",
    "            \"alpha\": 0.1,\n",
    "            \"device\": device,\n",
    "            \"lower_bound\": \"???\",\n",
    "            \"upper_bound\": \"???\",\n",
    "            \"return_mean_elites\": True,\n",
    "            \"clipped_normal\": False\n",
    "        }\n",
    "elif optimizer_type == \"mppi\":\n",
    "    optimizer_cfg = {\n",
    "            \"_target_\": \"mbrl.planning.MPPIOptimizer\",\n",
    "            \"num_iterations\": 5,\n",
    "            \"gamma\": 1.0,\n",
    "            \"population_size\": 500,\n",
    "            \"sigma\": 0.95,\n",
    "            \"beta\": 0.7,\n",
    "            \"lower_bound\": \"???\",\n",
    "            \"upper_bound\": \"???\",\n",
    "            \"device\": device,\n",
    "        }\n",
    "\n",
    "elif optimizer_type == \"icem\":\n",
    "    optimizer_cfg = {\n",
    "            \"_target_\": \"mbrl.planning.ICEMOptimizer\",\n",
    "            \"num_iterations\": 5,\n",
    "            \"elite_ratio\": 0.1,\n",
    "            \"population_size\": 500,\n",
    "            \"population_decay_factor\": 1.25,\n",
    "            \"colored_noise_exponent\": 2.0,\n",
    "            \"keep_elite_frac\": 0.1,\n",
    "            \"alpha\": 0.1,\n",
    "            \"lower_bound\": \"???\",\n",
    "            \"upper_bound\": \"???\",\n",
    "            \"device\": device,\n",
    "        }\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "\n",
    "agent_cfg = omegaconf.OmegaConf.create({\n",
    "    # this class evaluates many trajectories and picks the best one\n",
    "    \"_target_\": \"mbrl.planning.TrajectoryOptimizerAgent\",\n",
    "    \"planning_horizon\": 40,\n",
    "    \"replan_freq\": 1,\n",
    "    \"verbose\": False,\n",
    "    \"action_lb\": \"???\",\n",
    "    \"action_ub\": \"???\",\n",
    "    # this is the optimizer to generate and choose a trajectory\n",
    "    \"optimizer_cfg\": optimizer_cfg\n",
    "})\n",
    "\n",
    "agent = planning.create_trajectory_optim_agent_for_model(\n",
    "    model_env,\n",
    "    agent_cfg,\n",
    "    num_particles=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving config files\n",
    "config_filename = 'cfg_dict'\n",
    "config_dir = os.path.join(work_dir, config_filename)\n",
    "omegaconf.OmegaConf.save(config=cfg, f=config_dir) \n",
    "loaded = omegaconf.OmegaConf.load(config_dir)\n",
    "assert cfg == loaded\n",
    "\n",
    "agent_config_filename = 'agent_cfg'\n",
    "agent_config_dir = os.path.join(work_dir, agent_config_filename)\n",
    "omegaconf.OmegaConf.save(config=agent_cfg, f=agent_config_dir) \n",
    "loaded = omegaconf.OmegaConf.load(agent_config_dir)\n",
    "assert agent_cfg == loaded\n",
    "\n",
    "env_kwargs_filename = 'env_kwargs'\n",
    "env_kwargs_dir = os.path.join(work_dir, env_kwargs_filename)\n",
    "omegaconf.OmegaConf.save(config=env_kwargs, f=env_kwargs_dir) \n",
    "loaded = omegaconf.OmegaConf.load(env_kwargs_dir)\n",
    "assert env_kwargs == loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current goal index 0\n",
      "Position goal trajectory [[0.066897 0.180000 0.000000]]\n",
      "0\n",
      "[[ True  True  True]]\n",
      "[0.066897 0.180000 0.000000]\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "print(\"Current goal index\", env.targ_traj_list_id)\n",
    "print(\"Position goal trajectory\", env.traj_pos_workframe)\n",
    "# print(\"Orientation goal trajectory\", env.traj_rpy_workframe)\n",
    "# print(\"Orientation goal trajectory\", env.traj_orn_workframe)\n",
    "\n",
    "# All of this can be accessed through model_env.env\n",
    "print(model_env.env.targ_traj_list_id)\n",
    "print(model_env.env.traj_pos_workframe == env.traj_pos_workframe)\n",
    "print(model_env.env.goal_pos_workframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False]], device='cuda:0')\n",
      "tensor([[False],\n",
      "        [False],\n",
      "        [False]], device='cuda:0')\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# ----------------- Test termination function in model env -------------------------\n",
    "early_termination = env.terminate_early\n",
    "def termination(act: torch.Tensor, next_obs: torch.Tensor, rewards:  torch.Tensor) -> torch.Tensor:\n",
    "    '''\n",
    "    Criteria for terminating an episode. Should return a vector of dones of size \n",
    "    population_size x batch_size\n",
    "    '''\n",
    "\n",
    "    if 'reduced' in env.observation_mode: \n",
    "        tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "        # tcp_orn_to_goal_workframe = next_obs[:, 3:7]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 7:10]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 10:13]\n",
    "        cur_obj_pos_to_goal_workframe = next_obs[:, 13:16]\n",
    "        # cur_obj_orn_to_goal_workframe = next_obs[:, 16:20]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 20:23]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 23:26]\n",
    "\n",
    "        tcp_pos_workframe = tcp_pos_to_goal_workframe + goal_pos_workframe_batch\n",
    "        cur_obj_pos_workframe = cur_obj_pos_to_goal_workframe + goal_pos_workframe_batch\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_to_goal_workframe, axis=1)\n",
    "    \n",
    "    elif env.observation_mode == 'tactile_pose_data': \n",
    "\n",
    "        if env.planar_states == True: \n",
    "            # tcp_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            # tcp_pos_to_goal_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_to_goal_workframe[:, 2:4] = next_obs[:, 0:2]\n",
    "            cur_obj_pos_to_goal_workframe[:, 0:2]= next_obs[:, 2:4]\n",
    "            cur_obj_orn_to_goal_workframe[:, 2:4] = next_obs[:, 4:6]\n",
    "        else:\n",
    "            # tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_to_goal_workframe = next_obs[:, 0:4]\n",
    "            cur_obj_pos_to_goal_workframe = next_obs[:, 4:7]\n",
    "            cur_obj_orn_to_goal_workframe = next_obs[:, 7:11]\n",
    "\n",
    "        # Only take in the x and y coordinates\n",
    "        # tcp_pos_workframe = tcp_pos_to_goal_workframe[:, 0:2] + goal_pos_workframe_batch[:, 0:2]\n",
    "        cur_obj_pos_workframe = cur_obj_pos_to_goal_workframe[:, 0:2] + goal_pos_workframe_batch[:, 0:2]\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_to_goal_workframe, axis=1)\n",
    "            \n",
    "    elif env.observation_mode == 'tactile_pose_goal_excluded_data': \n",
    "\n",
    "        if env.planar_states == True:\n",
    "            tcp_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float64).to(device)\n",
    "            tcp_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float64).to(device)\n",
    "            cur_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float64).to(device)\n",
    "            cur_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float64).to(device)\n",
    "\n",
    "            tcp_pos_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_workframe[:, 2:4] = next_obs[:, 2:4]\n",
    "            cur_obj_pos_workframe[:, 0:2]= next_obs[:, 4:6]\n",
    "            cur_obj_orn_workframe[:, 2:4] = next_obs[:, 6:8]\n",
    "        else:   \n",
    "\n",
    "            tcp_pos_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_workframe = next_obs[:, 3:7]\n",
    "            cur_obj_pos_workframe = next_obs[:, 7:10]\n",
    "            cur_obj_orn_workframe = next_obs[:, 10:14]\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_workframe - goal_pos_workframe_batch, axis=1)\n",
    "\n",
    "        # calculate tcp to object orn\n",
    "        tcp_to_obj_orn = model_env.get_orn_dist(cur_obj_orn_workframe, tcp_orn_workframe)\n",
    "\n",
    "        tip_to_obj_pos = torch.linalg.norm(tcp_pos_workframe - cur_obj_pos_workframe, axis=1)\n",
    "\n",
    "    else:\n",
    "        tcp_pos_workframe = next_obs[:, 0:3]\n",
    "        # tcp_rpy_workframe = next_obs[:, 3:6]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 6:9]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 9:12]\n",
    "        cur_obj_pos_workframe = next_obs[:, 12:15]\n",
    "        # cur_obj_rpy_workframe = next_obs[:, 15:18]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 18:21]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 21:24]\n",
    "        # pred_goal_pos_workframe = next_obs[:, 24:27]\n",
    "        # pred_goal_rpy_workframe = next_obs[:, 27:30]\n",
    "\n",
    "        # Calculate distance between goal and current positon\n",
    "        obj_goal_pos_dist = torch.linalg.norm(cur_obj_pos_workframe - goal_pos_workframe_batch, axis=1)\n",
    "    \n",
    "    # print('Object position, ', cur_obj_pos_workframe)\n",
    "    # print('TCP position, ', tcp_pos_workframe)\n",
    "    # print(obj_goal_pos_dist)\n",
    "\n",
    "    # Set obj to goal to smaller than tolerance for testing\n",
    "    # obj_goal_pos_dist[1] = 0.001\n",
    "\n",
    "    # intiailise terminated vector\n",
    "    terminated = torch.zeros((batch_size, 1), dtype=bool).to(device)\n",
    "\n",
    "    # print(\"goal position batch before update \\n\", goal_pos_workframe_batch)\n",
    "    # print(\"goal index batch before update\", targ_traj_list_id_batch)\n",
    "\n",
    "    # Early termination if outside of the tcp limits\n",
    "    if early_termination:\n",
    "        outside_tcp_lims_idx = outside_tcp_lims(cur_obj_pos_workframe, tcp_to_obj_orn, tip_to_obj_pos)\n",
    "        terminated[outside_tcp_lims_idx] = True\n",
    "        rewards[outside_tcp_lims_idx] += env.terminated_early_penalty\n",
    "        # print(\"Outside TPC_lims, \", outside_tcp_lims(tcp_pos_workframe, cur_obj_pos_workframe, tip_to_obj_pos))\n",
    "\n",
    "    # update goals index if subgoal reached\n",
    "    targ_traj_list_id_batch[obj_goal_pos_dist < model_env.termination_pos_dist] += 1\n",
    "\n",
    "    # Terminated is true if last subgoal is reached\n",
    "    terminated[targ_traj_list_id_batch >= model_env.traj_n_points] = True\n",
    "    rewards[targ_traj_list_id_batch >= model_env.traj_n_points] += model_env.reached_goal_reward\n",
    "\n",
    "    # Update goal position batch for none terminated samples\n",
    "    goal_pos_workframe_batch[~terminated[:,0]] = traj_pos_workframe[targ_traj_list_id_batch[~terminated[:,0]]]\n",
    "\n",
    "    # print(\"obj to goal distance\", obj_goal_pos_dist)\n",
    "    # print(\"goal index batch\", targ_traj_list_id_batch)\n",
    "    # print(\"terminated batch\", terminated)\n",
    "    # print(\"goal position index not terminated\", targ_traj_list_id_batch[~terminated[:,0]])\n",
    "    # print(\"The none terminated goals to be updated\", traj_pos_workframe[targ_traj_list_id_batch[~terminated[:,0]]])\n",
    "    # print(\"The updated goals \\n\", goal_pos_workframe_batch)\n",
    "    return terminated\n",
    "\n",
    "def outside_tcp_lims(cur_obj_pos_workframe, tcp_to_obj_orn, tip_to_obj_pos):\n",
    "    # xyz_tcp_dist_to_obj = torch.linalg.norm(tcp_pos_workframe - cur_obj_pos_workframe)\n",
    "    return ((cur_obj_pos_workframe[:, 0] < env.robot.arm.TCP_lims[0,0]) | \n",
    "        (cur_obj_pos_workframe[:, 0] > env.robot.arm.TCP_lims[0,1]) | \n",
    "        (cur_obj_pos_workframe[:, 1] < env.robot.arm.TCP_lims[1,0]) | \n",
    "        (cur_obj_pos_workframe[:, 1] > env.robot.arm.TCP_lims[1,1]) | \n",
    "        (tcp_to_obj_orn > model_env.max_tcp_to_obj_orn) | \n",
    "        (tip_to_obj_pos > model_env.max_tip_to_obj_pos))\n",
    "        # (xyz_tcp_dist_to_obj > env.obj_width / 2))                # TODO: exiting episode when roughly lose contact\n",
    "\n",
    "\n",
    "# Reset environment\n",
    "batch_size = 3\n",
    "env.reset()\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "# Create goal batches (access through model_env)\n",
    "traj_pos_workframe = model_env.traj_pos_workframe.clone()\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch.clone()\n",
    "targ_traj_list_id_batch = model_env.targ_traj_list_id_batch\n",
    "# targ_traj_list_id_batch = torch.from_numpy(targ_traj_list_id_batch).long()\n",
    "# targ_traj_list_id_batch[0] = 11\n",
    "\n",
    "tcp_pos = torch.tensor([[0.1, 0.01, 0], [0.1, 0.01, 0], [0.1, 0.01, 0]]).to(device)\n",
    "obj_pos = tcp_pos + torch.tensor([[0.0, 0.1, 0.0], [0.0, 0, 0], [0, 0, 0]]).to(device)\n",
    "tcp_orn = euler_to_quaternion(torch.tensor([[0, 0, 0], [0, 0, 0], [0, 0, 0]])).to(device)\n",
    "obj_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi]])).to(device)\n",
    "tip_to_obj_orn = model_env.get_orn_dist(tcp_orn, obj_orn)\n",
    "\n",
    "obs = torch.randn(batch_size, obs_shape[0]).to(device)\n",
    "if \"reduced\" in env.observation_mode:\n",
    "    obs[:, :3] =  torch.tensor([[0.2, 0.05, 0.1], [0.2, 0.05, 0.1], [0.2, 0.05, 0.1]]) \n",
    "    obs[:, 13:16] = torch.tensor([[0.2, 0.05, 0.1], [0.2, 0.1, 0.1], [0.2, 0.05, 0.1]])\n",
    "elif env.observation_mode =='tactile_pose_data':\n",
    "    if env.planar_states == True:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.20, 0.01], [0.3, 0.01], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "        obs[:, 2:4] = torch.tensor([[0.4, 0.01], [0.35, 0.1], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "    else:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.20, 0.01], [0.3, 0.01], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "        obs[:, 4:6] = torch.tensor([[0.30, 0.01], [0.20, 0.09], [0.2, 0.01]]).to(device) - goal_pos_workframe_batch[:, 0:2]\n",
    "elif env.observation_mode == 'tactile_pose_goal_excluded_data': \n",
    "    if env.planar_states == True:\n",
    "        obs[:, 0:2] = tcp_pos[:, 0:2]\n",
    "        obs[:, 4:6] = obj_pos[:, 0:2]\n",
    "        obs[:, 2:4] = tcp_orn[:, 2:4]\n",
    "        obs[:, 6:8] = obj_orn[:, 2:4]\n",
    "    else:\n",
    "        # obs[:, 0:2] =  torch.tensor([[0.2, 0.01], [0.31, 0.01], [0.2, 0.01]]) \n",
    "        obs[:, 4:6] = torch.tensor([[0.31, 0.1], [0.20, 0.01], [0.2, 0.01]])\n",
    "\n",
    "else:\n",
    "    obs[:, :3] =  torch.tensor([[0.3, 0.1, 0.1], [0.3, 0.1, 0.1], [0.3, 0.1, 0.1]]) \n",
    "    obs[:, 12:15] = torch.tensor([[0.3, 0.1, 0.1], [0.3, 0.1, 0.1], [0.4, 0.1, 0.1]]) \n",
    "\n",
    "act = torch.randn(batch_size, 1).to(device)\n",
    "rewards_test = torch.zeros(batch_size, 1).to(device)\n",
    "rewards_push = torch.zeros(batch_size, 1).to(device)\n",
    "print(termination(act, obs, rewards_test))\n",
    "print(model_env.termination(act, obs, rewards_push))\n",
    "print(rewards_test)\n",
    "print(rewards_push)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False], device='cuda:0')\n",
      "tensor([[False],\n",
      "        [False]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# ---------------- Test early termination ------------------------\n",
    "early_termination = True\n",
    "\n",
    "tcp_pos_workframe = torch.tensor([[0.1, 0.01, 0], [0.1, 0.01, 0]]).to(device)\n",
    "cur_obj_pos_workframe = tcp_pos_workframe + torch.tensor([[0.1, 0.0, 0.0], [0.0, 0, 0]]).to(device) # The first sample for obj_pos is out of y_lims\n",
    "tcp_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 10/180*np.pi]])).to(device)\n",
    "obj_orn = euler_to_quaternion(torch.tensor([[0, 0, 10/180*np.pi], [0, 0, 30/180*np.pi]])).to(device)\n",
    "tip_to_obj_orn = model_env.get_orn_dist(tcp_orn, obj_orn)\n",
    "tip_to_obj_pos = torch.linalg.norm(tcp_pos_workframe - cur_obj_pos_workframe,  axis=1)\n",
    "print(outside_tcp_lims(cur_obj_pos_workframe, tip_to_obj_orn, tip_to_obj_pos))\n",
    "\n",
    "batch_size = 2\n",
    "env.reset()\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "# Create goal batches (access through model_env)\n",
    "traj_pos_workframe = model_env.traj_pos_workframe\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch\n",
    "targ_traj_list_id_batch = model_env.targ_traj_list_id_batch\n",
    "\n",
    "obs = torch.randn(batch_size, 30).to(device)\n",
    "act = torch.randn(batch_size, 1).to(device)\n",
    "rewards = torch.randn(batch_size).to(device)\n",
    "if \"reduced\" in env.observation_mode:\n",
    "    obs[:, 0:3] = tcp_pos_workframe\n",
    "    obs[:, 13:16] = cur_obj_pos_workframe\n",
    "elif  env.observation_mode == 'tactile_pose_data':\n",
    "    if env.planar_states == True:\n",
    "        # obs[:, 0:2] = tcp_pos_workframe[:, 0:2] - goal_pos_workframe_batch[:, 0:2]\n",
    "        obs[:, 2:4] = cur_obj_pos_workframe[:, 0:2] - goal_pos_workframe_batch[:, 0:2]\n",
    "    else:\n",
    "        # obs[:, 0:3] = tcp_pos_workframe - goal_pos_workframe_batch\n",
    "        obs[:, 4:7] = cur_obj_pos_workframe- goal_pos_workframe_batch  \n",
    "elif env.observation_mode == 'tactile_pose_goal_excluded_data':\n",
    "        if env.planar_states == True:\n",
    "            obs[:, 0:2] = tcp_pos_workframe[:, 0:2]\n",
    "            obs[:, 2:4] = tcp_orn[:, 2:4]\n",
    "            obs[:, 4:6] = cur_obj_pos_workframe[:, 0:2]\n",
    "            obs[:, 6:8] = obj_orn[:, 2:4]\n",
    "        else:\n",
    "            # obs[:, 0:3] = tcp_pos_workframe\n",
    "            obs[:, 4:7] = cur_obj_pos_workframe\n",
    "else:\n",
    "    obs[:, 0:3] = tcp_pos_workframe\n",
    "    obs[:, 12:15] = cur_obj_pos_workframe\n",
    "print(termination(_, obs, rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.055750083974555\n",
      "tensor([[-1.0557],\n",
      "        [-1.0557]], device='cuda:0')\n",
      "tensor([[-1.0557],\n",
      "        [-1.0557]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# --------------- Test reward function  in model env-------------------------------\n",
    "def xyz_obj_dist_to_goal(cur_obj_pos_workframe):\n",
    "\n",
    "    # obj to goal distance\n",
    "    return torch.linalg.norm(cur_obj_pos_workframe - goal_pos_workframe_batch, axis=1)\n",
    "\n",
    "def get_pos_dist(pos_dist_vector):\n",
    "\n",
    "    # obj to goal distance\n",
    "    return torch.linalg.norm(pos_dist_vector, axis=1)\n",
    "\n",
    "def orn_obj_dist_to_goal_rpy(cur_obj_rpy_workframe):\n",
    "    cur_obj_orn_workframe = euler_to_quaternion(cur_obj_rpy_workframe)\n",
    "    inner_product = torch.sum(goal_orn_workframe_batch*cur_obj_orn_workframe, 1)\n",
    "    return torch.arccos(torch.clip(2 * (inner_product ** 2) - 1, -1, 1))\n",
    "\n",
    "def orn_obj_dist_to_goal_orn(cur_obj_orn_workframe):\n",
    "    inner_product = torch.sum(goal_orn_workframe_batch*cur_obj_orn_workframe, 1)\n",
    "    return torch.arccos(torch.clip(2 * (inner_product ** 2) - 1, -1, 1))\n",
    "\n",
    "def get_orn_norm(orn_dist_vector):\n",
    "    \"\"\"\n",
    "    Distance between the current obj orientation and goal orientation.\n",
    "    \"\"\"\n",
    "    dist = torch.arccos(torch.clip(\n",
    "        (2 * (orn_dist_vector[:, 3]**2)) - 1, -1, 1))\n",
    "    return dist\n",
    "\n",
    "def get_orn_dist(orn_dist_vector_1, orn_dist_vector_2):\n",
    "    inner_product = torch.sum(orn_dist_vector_1*orn_dist_vector_2, 1)\n",
    "    return torch.arccos(torch.clip(2 * (inner_product ** 2) - 1, -1, 1))\n",
    "\n",
    "def cos_tcp_dist_to_obj(cur_obj_rpy_workframe, tcp_rpy_workframe):\n",
    "    \"\"\"\n",
    "    Cos distance from current orientation of the TCP to the current\n",
    "    orientation of the object\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = cur_obj_rpy_workframe.shape[0]\n",
    "\n",
    "    # tip normal to object normal\n",
    "    cur_obj_orn_workframe = euler_to_quaternion(cur_obj_rpy_workframe)\n",
    "    obj_rot_matrix_workframe = quaternion_rotation_matrix(cur_obj_orn_workframe)\n",
    "    obj_rot_matrix_workframe = torch.reshape(obj_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    obj_init_vector_workframe = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32).to(device)\n",
    "    obj_vector_workframe = torch.matmul(obj_rot_matrix_workframe, obj_init_vector_workframe)\n",
    "    # obj_vector_workframe = obj_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    tcp_orn_workframe = euler_to_quaternion(tcp_rpy_workframe)\n",
    "    tip_rot_matrix_workframe = quaternion_rotation_matrix(tcp_orn_workframe)\n",
    "    tip_rot_matrix_workframe  = torch.reshape(tip_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    tip_init_vector_workframe  = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float32).to(device)\n",
    "    tip_vector_workframe  = torch.matmul(tip_rot_matrix_workframe, tip_init_vector_workframe)\n",
    "    # tip_vector_workframe = tip_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    obj_tip_dot_product = torch.sum(obj_vector_workframe*tip_vector_workframe, 1)\n",
    "    cos_sim_workfrfame = obj_tip_dot_product / (\n",
    "        torch.linalg.norm(obj_vector_workframe, axis=1) * torch.linalg.norm(tip_vector_workframe, axis=1)\n",
    "    )\n",
    "    cos_dist_workframe = 1 - cos_sim_workfrfame\n",
    "\n",
    "    return cos_dist_workframe\n",
    "\n",
    "def cos_tcp_dist_to_obj_reduced(cur_obj_orn_to_goal_workframe, tcp_orn_to_goal_workframe):\n",
    "    \"\"\"\n",
    "    Cos distance from current orientation of the TCP to the current\n",
    "    orientation of the object\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = cur_obj_orn_to_goal_workframe.shape[0]\n",
    "\n",
    "    # tip normal to object normal\n",
    "    obj_rot_matrix_workframe = quaternion_rotation_matrix(cur_obj_orn_to_goal_workframe)\n",
    "    obj_rot_matrix_workframe = torch.reshape(obj_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    # obj_init_vector_workframe = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)\n",
    "    # obj_vector_workframe = torch.matmul(obj_rot_matrix_workframe, obj_init_vector_workframe)\n",
    "    obj_vector_workframe = obj_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    tip_rot_matrix_workframe = quaternion_rotation_matrix(tcp_orn_to_goal_workframe)\n",
    "    tip_rot_matrix_workframe  = torch.reshape(tip_rot_matrix_workframe, (batch_size, 3, 3))\n",
    "    # tip_init_vector_workframe  = torch.tensor([1.0, 0.0, 0.0], dtype=torch.float64)\n",
    "    # tip_vector_workframe  = torch.matmul(tip_rot_matrix_workframe, tip_init_vector_workframe)\n",
    "    tip_vector_workframe = tip_rot_matrix_workframe[:, :, 0]\n",
    "\n",
    "    obj_tip_dot_product = torch.sum(obj_vector_workframe*tip_vector_workframe, 1)\n",
    "    cos_sim_workfrfame = obj_tip_dot_product / (\n",
    "        torch.linalg.norm(obj_vector_workframe, axis=1) * torch.linalg.norm(tip_vector_workframe, axis=1)\n",
    "    )\n",
    "    cos_dist_workframe = 1 - cos_sim_workfrfame \n",
    "\n",
    "    return cos_dist_workframe\n",
    "\n",
    "def cos_tcp_Rz_dist_to_obj(cos_cur_obj_Rz_to_goal_workframe, cos_tcp_Rz_to_goal_workframe):\n",
    "    cos_sim_workframe = torch.cos(\n",
    "        torch.arccos(cos_tcp_Rz_to_goal_workframe) - torch.arccos(cos_cur_obj_Rz_to_goal_workframe)\n",
    "        )\n",
    "    return 1 - cos_sim_workframe\n",
    "\n",
    "def reward(act: torch.Tensor, next_obs: torch.Tensor) -> torch.Tensor:\n",
    "    '''\n",
    "    Caculate the reward given a batch of observations \n",
    "    '''\n",
    "\n",
    "    batch_size = next_obs.shape[0]\n",
    "\n",
    "    if 'reduced' in env.observation_mode: \n",
    "        # tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "        tcp_orn_to_goal_workframe = next_obs[:, 3:7]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 7:10]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 10:13]\n",
    "        cur_obj_pos_to_goal_workframe = next_obs[:, 13:16]\n",
    "        cur_obj_orn_to_goal_workframe = next_obs[:, 16:20]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 20:23]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 23:26]\n",
    "\n",
    "        obj_goal_pos_dist = get_pos_dist(cur_obj_pos_to_goal_workframe)\n",
    "        obj_goal_orn_dist = get_orn_norm(cur_obj_orn_to_goal_workframe)\n",
    "        tip_obj_orn_dist = cos_tcp_dist_to_obj_reduced(cur_obj_orn_to_goal_workframe, tcp_orn_to_goal_workframe)\n",
    "\n",
    "        print(obj_goal_orn_dist)\n",
    "    elif env.observation_mode == 'tactile_pose_data': \n",
    "        if env.planar_states == True: \n",
    "            # tcp_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_to_goal_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_to_goal_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            # tcp_pos_to_goal_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_to_goal_workframe[:, 2:4] = next_obs[:, 0:2]\n",
    "            cur_obj_pos_to_goal_workframe[:, 0:2]= next_obs[:, 2:4]\n",
    "            cur_obj_orn_to_goal_workframe[:, 2:4] = next_obs[:, 4:6]\n",
    "        else:\n",
    "            # tcp_pos_to_goal_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_to_goal_workframe = next_obs[:, 0:4]\n",
    "            cur_obj_pos_to_goal_workframe = next_obs[:, 4:7]\n",
    "            cur_obj_orn_to_goal_workframe = next_obs[:, 7:11]\n",
    "            \n",
    "        obj_goal_pos_dist = get_pos_dist(cur_obj_pos_to_goal_workframe)\n",
    "        obj_goal_orn_dist = get_orn_norm(cur_obj_orn_to_goal_workframe)\n",
    "        tip_obj_orn_dist = get_orn_dist(cur_obj_orn_to_goal_workframe, tcp_orn_to_goal_workframe)\n",
    "\n",
    "    elif env.observation_mode == 'tactile_pose_goal_excluded_data':\n",
    "        if env.planar_states == True:\n",
    "            # tcp_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            tcp_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "            cur_obj_pos_workframe = torch.zeros((len(next_obs), 3), dtype=torch.float32).to(device)\n",
    "            cur_obj_orn_workframe = torch.zeros((len(next_obs), 4), dtype=torch.float32).to(device)\n",
    "\n",
    "            # tcp_pos_workframe[:, 0:2] = next_obs[:, 0:2]\n",
    "            tcp_orn_workframe[:, 2:4] = next_obs[:, 2:4]\n",
    "            cur_obj_pos_workframe[:, 0:2]= next_obs[:, 4:6]\n",
    "            cur_obj_orn_workframe[:, 2:4] = next_obs[:, 6:8]\n",
    "        else:   \n",
    "            # tcp_pos_workframe = next_obs[:, 0:3]\n",
    "            tcp_orn_workframe = next_obs[:, 0:4]\n",
    "            cur_obj_pos_workframe = next_obs[:, 4:7]\n",
    "            cur_obj_orn_workframe = next_obs[:, 7:11]\n",
    "\n",
    "        obj_goal_pos_dist = xyz_obj_dist_to_goal(cur_obj_pos_workframe)\n",
    "        obj_goal_orn_dist = orn_obj_dist_to_goal_orn(cur_obj_orn_workframe)\n",
    "        tip_obj_orn_dist = get_orn_dist(cur_obj_orn_workframe, tcp_orn_workframe)\n",
    "        \n",
    "    else:\n",
    "        # tcp_pos_workframe = next_obs[:, 0:3]\n",
    "        tcp_rpy_workframe = next_obs[:, 3:6]\n",
    "        # tcp_lin_vel_workframe = next_obs[:, 6:9]\n",
    "        # tcp_ang_vel_workframe = next_obs[:, 9:12]\n",
    "        cur_obj_pos_workframe = next_obs[:, 12:15]\n",
    "        cur_obj_rpy_workframe = next_obs[:, 15:18]\n",
    "        # cur_obj_lin_vel_workframe = next_obs[:, 18:21]\n",
    "        # cur_obj_ang_vel_workframe = next_obs[:, 21:24]\n",
    "        # pred_goal_pos_workframe = next_obs[:, 24:27]\n",
    "        # pred_goal_rpy_workframe = next_obs[:, 27:30]\n",
    "\n",
    "        obj_goal_pos_dist = xyz_obj_dist_to_goal(cur_obj_pos_workframe)\n",
    "        obj_goal_orn_dist = orn_obj_dist_to_goal_rpy(cur_obj_rpy_workframe)\n",
    "        tip_obj_orn_dist = cos_tcp_dist_to_obj(cur_obj_rpy_workframe, tcp_rpy_workframe)\n",
    "\n",
    "    reward = -(\n",
    "        (env.W_obj_goal_pos * obj_goal_pos_dist)\n",
    "        + (env.W_obj_goal_orn * obj_goal_orn_dist)\n",
    "        + (env.W_tip_obj_orn * tip_obj_orn_dist)\n",
    "        )\n",
    "    reward = reward[:, None]\n",
    "\n",
    "    return reward\n",
    "\n",
    "# Create observation and goal batch \n",
    "batch_size = 2\n",
    "obs = env.reset()\n",
    "for i in range(1):\n",
    "    obs, _, done, _ = env.step(env.action_space.sample())\n",
    "obs = torch.tensor(obs).to(torch.float32).to(device)\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "obs_batch = torch.tile(obs, (batch_size,) + tuple([1] * obs.ndim))\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch\n",
    "goal_orn_workframe_batch = model_env.goal_orn_workframe_batch\n",
    "\n",
    "print(env.dense_reward())\n",
    "print(reward(_, obs_batch))\n",
    "print(model_env.reward(_, obs_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.000005 0.000004 -0.666846 0.745195]\n",
      "tensor([[ 0.0000,  0.0000, -0.6668,  0.7452],\n",
      "        [ 0.0000,  0.0000, -0.6668,  0.7452]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# check update goal function\n",
    "batch_size = 2\n",
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    obs, _, done, _ = env.step(env.action_space.sample())\n",
    "obs = torch.tensor(obs).to(torch.float32).to(device)\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "obs_batch = torch.tile(obs, (batch_size,) + tuple([1] * obs.ndim))\n",
    "\n",
    "print(env.goal_orn_workframe)\n",
    "model_env.update_goal_orn(obs_batch)\n",
    "print(model_env.goal_orn_workframe_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8500],\n",
      "        [-1.1309],\n",
      "        [-0.7105],\n",
      "        ...,\n",
      "        [-2.8245],\n",
      "        [-1.8846],\n",
      "        [-2.7697]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "tensor([[-0.8500],\n",
      "        [-1.1309],\n",
      "        [-0.7105],\n",
      "        ...,\n",
      "        [-2.8245],\n",
      "        [-1.8846],\n",
      "        [-2.7697]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n",
      "True\n",
      "True\n",
      "tensor([[-200.8500],\n",
      "        [-201.1309],\n",
      "        [-200.7105],\n",
      "        ...,\n",
      "        [-202.8245],\n",
      "        [-201.8846],\n",
      "        [-202.7697]], device='cuda:0', grad_fn=<AsStridedBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Test reward and terminal function using next_observ from model.sample()\n",
    "planning_horizon = agent.optimizer.horizon\n",
    "# initialise action sequence\n",
    "action_lb = env.action_space.low.tolist()\n",
    "action_ub = env.action_space.high.tolist()\n",
    "initial_solution = (((torch.tensor(action_lb) + torch.tensor(action_ub)) / 2)\n",
    "            .float().to(device)\n",
    "        )\n",
    "initial_solution = initial_solution.repeat((planning_horizon, 1))\n",
    "mu, dispersion = agent.optimizer.optimizer._init_population_params(initial_solution)\n",
    "action_sequences = torch.zeros((500,) + initial_solution.shape).to(device)\n",
    "action_sequences = agent.optimizer.optimizer._sample_population(mu, dispersion, action_sequences)\n",
    "\n",
    "# Intialise state and create model state for model input\n",
    "env.reset()\n",
    "for i in range(100):\n",
    "    obs, _, done, _ = env.step(env.action_space.sample())\n",
    "initial_state = obs\n",
    "tiling_shape = (20 * 500,) + tuple(\n",
    "    [1] * initial_state.ndim\n",
    ")\n",
    "initial_obs_batch = np.tile(initial_state, tiling_shape).astype(np.float32)\n",
    "model_state = model_env.reset(initial_obs_batch, return_as_np=False)\n",
    "\n",
    "# get action for time step\n",
    "action_for_step = action_sequences[:, 0, :]\n",
    "action_batch = torch.repeat_interleave(\n",
    "                    action_for_step, 20, dim=0\n",
    "                )\n",
    "\n",
    "# Get next observation from model\n",
    "(\n",
    "    next_observs,\n",
    "    pred_rewards,\n",
    "    pred_terminals,\n",
    "    next_model_state,\n",
    ") = model_env.dynamics_model.sample(\n",
    "    action_batch,\n",
    "    model_state,\n",
    "    deterministic=False,\n",
    "    rng=model_env._rng,\n",
    ")\n",
    "\n",
    "# Next obervation types\n",
    "# print(next_observs.type())\n",
    "# print(next_observs.dtype)\n",
    "# print(next_observs.shape)\n",
    "\n",
    "# Create observation and goal batch \n",
    "batch_size = next_observs.shape[0]\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "# Get global variables needed for reward function\n",
    "goal_pos_workframe_batch = model_env.goal_pos_workframe_batch\n",
    "goal_orn_workframe_batch = model_env.goal_orn_workframe_batch\n",
    "\n",
    "print(reward(_, next_observs))\n",
    "print(model_env.reward(_, next_observs))\n",
    "print(any((reward(_, next_observs) == model_env.reward(_, next_observs))))\n",
    "\n",
    "# Get the global variables needed for termination function\n",
    "traj_pos_workframe = model_env.traj_pos_workframe\n",
    "targ_traj_list_id_batch = model_env.targ_traj_list_id_batch\n",
    "random_reward = reward(_, next_observs)\n",
    "\n",
    "# print(termination(_, next_observs))\n",
    "# print(model_env.termination(_, next_observs))\n",
    "# print(model_env.termination_fn(act, next_observs))\n",
    "print(all((termination(_, next_observs, random_reward) == model_env.termination(_, next_observs, random_reward))))\n",
    "print(random_reward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Test evaluation_action_sequences\n",
    "planning_horizon = agent.optimizer.horizon\n",
    "# initialise action sequence\n",
    "# action_lb = env.action_space.low.tolist()\n",
    "# action_ub = env.action_space.high.tolist()\n",
    "# initial_solution = (((torch.tensor(action_lb) + torch.tensor(action_ub)) / 2)\n",
    "#             .float()\n",
    "#         )\n",
    "# initial_solution = initial_solution.repeat((15, 1))\n",
    "# mu, dispersion = agent.optimizer.optimizer._init_population_params(initial_solution)\n",
    "# action_sequences = torch.zeros((500,) + initial_solution.shape)\n",
    "# action_sequences = agent.optimizer.optimizer._sample_population(mu, dispersion, action_sequences)\n",
    "# # print(initial_solution.shape)\n",
    "\n",
    "# create random action sequences\n",
    "initial_solution = torch.from_numpy(np.array([env.action_space.sample() for _ in range(planning_horizon)])).float().to(device)\n",
    "# print(initial_solution.shape)\n",
    "mu, dispersion = agent.optimizer.optimizer._init_population_params(initial_solution)\n",
    "action_sequences = torch.zeros((500,) + initial_solution.shape).to(device)\n",
    "action_sequences = agent.optimizer.optimizer._sample_population(mu, dispersion, action_sequences)\n",
    "\n",
    "# Initialise environment\n",
    "initial_state = env.reset()\n",
    "\n",
    "# evaluate sequences\n",
    "print(model_env.evaluate_action_sequences(action_sequences, initial_state, 20).shape)\n",
    "print(any(model_env.targ_traj_list_id_batch!=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = [0.0]\n",
    "val_scores = [0.0]\n",
    "\n",
    "def train_callback(_model, _total_calls, _epoch, tr_loss, val_score, _best_val):\n",
    "    train_losses.append(tr_loss)\n",
    "    val_scores.append(val_score.mean().item())   # this returns val score per ensemble model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x270 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def update_axes(_axs, _frame, _text, _trial, _steps_trial, _plan_time, _train_time, _all_rewards, _goal_reached, _train_loss, _val_loss, force_update=False):\n",
    "    if not force_update and (_steps_trial % 10 != 0):\n",
    "        return\n",
    "    _axs[0].imshow(_frame)\n",
    "    _axs[0].set_xticks([])\n",
    "    _axs[0].set_yticks([])\n",
    "    _axs[0].tick_params(axis='x', colors='white')\n",
    "    _axs[0].tick_params(axis='y', colors='white')\n",
    "    _axs[1].clear()\n",
    "    _axs[1].set_xlim([0, num_trials + .1])\n",
    "    _axs[1].set_ylim([min(_all_rewards), 0])\n",
    "    _axs[1].set_xlabel(\"Trial\")\n",
    "    _axs[1].set_ylabel(\"Trial reward\")\n",
    "    _axs[1].xaxis.label.set_color('white')\n",
    "    _axs[1].yaxis.label.set_color('white')\n",
    "    _axs[1].tick_params(axis='x', colors='white')\n",
    "    _axs[1].tick_params(axis='y', colors='white')\n",
    "    _axs[1].plot(_all_rewards, 'bs-', _goal_reached, 'rs')\n",
    "    _text.set_text(\"Trial {}: {} steps\\nTrain Loss: {:.2f}\\nVal Loss: {:.3g}\\nPlan time: {:.2f} s/step\\nTrain time: {:.2f} s\".format(_trial + 1, _steps_trial, _train_loss, _val_loss, _plan_time, _train_time))\n",
    "    display.display(plt.gcf())  \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "text_kwargs = dict(ha='center', va='center', fontsize=28, color='C1')\n",
    "def update_axes_text(_axs, _trial, _steps_trial, _plan_time, _train_time, _all_rewards, _goal_reached, _train_loss, _val_loss, force_update=False):\n",
    "    if not force_update and (_steps_trial % 10 != 0):\n",
    "        return\n",
    "    _axs[0].clear()\n",
    "    _axs[0].text(0.5, 0.5, \n",
    "    \"Trial {}: {} steps\\nTrain Loss: {:.2f}\\nVal Loss: {:.3g}\\nPlan time: {:.2f} s/step\\nTrain time: {:.2f} s\".format(_trial + 1, _steps_trial, _train_loss, _val_loss, _plan_time, _train_time), **text_kwargs)\n",
    "    _axs[1].clear()\n",
    "    _axs[1].set_xlim([0, num_trials + .1])\n",
    "    _axs[1].set_ylim([min(_all_rewards), 0])\n",
    "    _axs[1].set_xlabel(\"Trial\")\n",
    "    _axs[1].set_ylabel(\"Trial reward\")\n",
    "    _axs[1].xaxis.label.set_color('white')\n",
    "    _axs[1].yaxis.label.set_color('white')\n",
    "    _axs[1].tick_params(axis='x', colors='white')\n",
    "    _axs[1].tick_params(axis='y', colors='white')\n",
    "    _axs[1].plot(_all_rewards, 'bs-', _goal_reached, 'rs')\n",
    "    display.display(plt.gcf())  \n",
    "    display.clear_output(wait=True)\n",
    "\n",
    "# Test plot function\n",
    "env.reset()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "ax_text = axs[0].text(130, 80, \"\")\n",
    "ax_text.set_color('white')\n",
    "all_rewards = np.random.randint(-500, 0, num_trials + 1)\n",
    "goal_reached = np.random.randint(-500, 0, num_trials + 1)\n",
    "steps = np.sort(np.random.randint(0,10000, len(all_rewards)))\n",
    "plan_time = np.random.rand()\n",
    "train_time = np.random.rand()\n",
    "# update_axes(axs,env.render(mode=\"rgb_array\"),  ax_text, 0, 0, plan_time, train_time, all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)\n",
    "update_axes_text(axs, 0, 0, plan_time, train_time, all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_states_from_obs(obs):\n",
    "    if \"goal_excluded\" in env.observation_mode:\n",
    "        if env.planar_states == True:\n",
    "            # tcp_pos_workframe = np.zeros(3)\n",
    "            # tcp_orn_workframe = np.zeros(4)\n",
    "            cur_obj_pos_workframe = np.zeros(3)\n",
    "            cur_obj_orn_workframe = np.zeros(4)\n",
    "\n",
    "            # tcp_pos_workframe[0:2] = obs[0:2]\n",
    "            # tcp_orn_workframe[2:4] = obs[2:4]\n",
    "            cur_obj_pos_workframe[0:2]= obs[4:6]\n",
    "            cur_obj_orn_workframe[2:4] = obs[6:8]\n",
    "        else:   \n",
    "            # tcp_pos_workframe = obs[0:3]\n",
    "            # tcp_orn_workframe = obs[0:4]\n",
    "            cur_obj_pos_workframe = obs[4:7]\n",
    "            # cur_obj_orn_workframe = obs[7:11]\n",
    "\n",
    "    else:\n",
    "        if env.planar_states == True: \n",
    "            # tcp_pos_to_goal_workframe = np.zeros(3)\n",
    "            # tcp_orn_to_goal_workframe = np.zeros(4)\n",
    "            cur_obj_pos_to_goal_workframe = np.zeros(3)\n",
    "            # cur_obj_orn_to_goal_workframe = np.zeros(4)\n",
    "\n",
    "            # tcp_pos_to_goal_workframe[0:2] = obs[0:2]\n",
    "            # tcp_orn_to_goal_workframe[2:4] = obs[0:2]\n",
    "            cur_obj_pos_to_goal_workframe[0:2]= obs[2:4]\n",
    "            # cur_obj_orn_to_goal_workframe[2:4] = obs[4:6]\n",
    "        else:\n",
    "            # tcp_pos_to_goal_workframe = obs[0:3]\n",
    "            # tcp_orn_to_goal_workframe = obs[0:4]\n",
    "            cur_obj_pos_to_goal_workframe = obs[4:7]\n",
    "            # cur_obj_orn_to_goal_workframe = obs[7:11]\n",
    "\n",
    "        # tcp_pos_workframe = obs[0:3] + env.goal_pos_workframe\n",
    "        cur_obj_pos_workframe = cur_obj_pos_to_goal_workframe + env.goal_pos_workframe\n",
    "\n",
    "    return cur_obj_pos_workframe, cur_obj_orn_workframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# --- Doing env step using the agent and adding to model dataset ---\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m start_plan_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m next_obs, reward, done, info \u001b[39m=\u001b[39m common_util\u001b[39m.\u001b[39;49mstep_env_and_add_to_buffer(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=95'>96</a>\u001b[0m     env, obs, agent, {}, replay_buffer)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=96'>97</a>\u001b[0m plan_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_plan_time\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=98'>99</a>\u001b[0m update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bdaffyduck/home/qt21590/Documents/Projects/tactile_gym_mbrl/mbrl-lib/notebooks/object_pushing_pets_example.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=99'>100</a>\u001b[0m     all_rewards, goal_reached, train_losses[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], val_scores[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/util/common.py:603\u001b[0m, in \u001b[0;36mstep_env_and_add_to_buffer\u001b[0;34m(env, obs, agent, agent_kwargs, replay_buffer, callback, agent_uses_low_dim_obs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     agent_obs \u001b[39m=\u001b[39m obs\n\u001b[0;32m--> 603\u001b[0m action \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mact(agent_obs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49magent_kwargs)\n\u001b[1;32m    604\u001b[0m next_obs, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m    605\u001b[0m replay_buffer\u001b[39m.\u001b[39madd(obs, action, next_obs, reward, done)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:684\u001b[0m, in \u001b[0;36mTrajectoryOptimizerAgent.act\u001b[0;34m(self, obs, optimizer_callback, **_kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrajectory_eval_fn(obs, action_sequences)\n\u001b[1;32m    683\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 684\u001b[0m plan \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m    685\u001b[0m     trajectory_eval_fn, callback\u001b[39m=\u001b[39;49moptimizer_callback\n\u001b[1;32m    686\u001b[0m )\n\u001b[1;32m    687\u001b[0m plan_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m    689\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactions_to_use\u001b[39m.\u001b[39mextend([a \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m plan[: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplan_freq]])\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:558\u001b[0m, in \u001b[0;36mTrajectoryOptimizer.optimize\u001b[0;34m(self, trajectory_eval_fn, callback)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[1;32m    540\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    541\u001b[0m     trajectory_eval_fn: Callable[[torch\u001b[39m.\u001b[39mTensor], torch\u001b[39m.\u001b[39mTensor],\n\u001b[1;32m    542\u001b[0m     callback: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    543\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    544\u001b[0m     \u001b[39m\"\"\"Runs the trajectory optimization.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \n\u001b[1;32m    546\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m        (tuple of np.ndarray and float): the best action sequence.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m     best_solution \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m    559\u001b[0m         trajectory_eval_fn,\n\u001b[1;32m    560\u001b[0m         x0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprevious_solution,\n\u001b[1;32m    561\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    562\u001b[0m     )\n\u001b[1;32m    563\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_last_solution:\n\u001b[1;32m    564\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_solution \u001b[39m=\u001b[39m best_solution\u001b[39m.\u001b[39mroll(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplan_freq, dims\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:468\u001b[0m, in \u001b[0;36mICEMOptimizer.optimize\u001b[0;34m(self, obj_fun, x0, callback, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         population \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((population, kept_elites), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 468\u001b[0m values \u001b[39m=\u001b[39m obj_fun(population)\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    471\u001b[0m     callback(population, values, i)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:681\u001b[0m, in \u001b[0;36mTrajectoryOptimizerAgent.act.<locals>.trajectory_eval_fn\u001b[0;34m(action_sequences)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrajectory_eval_fn\u001b[39m(action_sequences):\n\u001b[0;32m--> 681\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrajectory_eval_fn(obs, action_sequences)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/planning/trajectory_opt.py:744\u001b[0m, in \u001b[0;36mcreate_trajectory_optim_agent_for_model.<locals>.trajectory_eval_fn\u001b[0;34m(initial_state, action_sequences)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrajectory_eval_fn\u001b[39m(initial_state, action_sequences):\n\u001b[0;32m--> 744\u001b[0m     \u001b[39mreturn\u001b[39;00m model_env\u001b[39m.\u001b[39;49mevaluate_action_sequences(\n\u001b[1;32m    745\u001b[0m         action_sequences, initial_state\u001b[39m=\u001b[39;49minitial_state, num_particles\u001b[39m=\u001b[39;49mnum_particles\n\u001b[1;32m    746\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/models/model_env_pushing.py:594\u001b[0m, in \u001b[0;36mModelEnvPushing.evaluate_action_sequences\u001b[0;34m(self, action_sequences, initial_state, num_particles)\u001b[0m\n\u001b[1;32m    590\u001b[0m action_for_step \u001b[39m=\u001b[39m action_sequences[:, time_step, :]\n\u001b[1;32m    591\u001b[0m action_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrepeat_interleave(\n\u001b[1;32m    592\u001b[0m     action_for_step, num_particles, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    593\u001b[0m )\n\u001b[0;32m--> 594\u001b[0m _, rewards, dones, model_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(\n\u001b[1;32m    595\u001b[0m     action_batch, model_state, sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    596\u001b[0m )\n\u001b[1;32m    597\u001b[0m rewards[terminated] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    598\u001b[0m terminated \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m dones\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/models/model_env_pushing.py:143\u001b[0m, in \u001b[0;36mModelEnvPushing.step\u001b[0;34m(self, actions, model_state, sample)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[39m# Update goal orn in mpc only if current obs outside of sensitive zone\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmpc_goal_orn_update \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mxyz_obj_dist_to_goal() \u001b[39m>\u001b[39m \u001b[39m0.1\u001b[39m: \n\u001b[0;32m--> 143\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_goal_orn(next_observs)\n\u001b[1;32m    145\u001b[0m rewards \u001b[39m=\u001b[39m (\n\u001b[1;32m    146\u001b[0m     pred_rewards\n\u001b[1;32m    147\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreward_fn(actions, next_observs)\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    150\u001b[0m dones \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtermination_fn(actions, next_observs, rewards)\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/models/model_env_pushing.py:224\u001b[0m, in \u001b[0;36mModelEnvPushing.update_goal_orn\u001b[0;34m(self, next_obs)\u001b[0m\n\u001b[1;32m    220\u001b[0m         goal_rpy_workframe_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(next_obs), \u001b[39m3\u001b[39m), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    221\u001b[0m         goal_rpy_workframe_batch[:, \u001b[39m2\u001b[39m] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39matan2(\u001b[39m-\u001b[39mnext_obs[:, \u001b[39m5\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoal_pos_workframe_batch[:, \u001b[39m1\u001b[39m], \n\u001b[1;32m    222\u001b[0m                                                     \u001b[39m-\u001b[39mnext_obs[:, \u001b[39m4\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoal_pos_workframe_batch[:, \u001b[39m0\u001b[39m])\n\u001b[0;32m--> 224\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgoal_orn_workframe_batch \u001b[39m=\u001b[39m euler_to_quaternion(goal_rpy_workframe_batch)\n\u001b[1;32m    226\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39mNotImplemented\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Projects/tactile_gym_mbrl/mbrl-lib/mbrl/util/math.py:528\u001b[0m, in \u001b[0;36meuler_to_quaternion\u001b[0;34m(euler)\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meuler_to_quaternion\u001b[39m(euler: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    519\u001b[0m     \u001b[39m''' \u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[39m    Convert a batch of euler angles to a batch of 4 dimenstional quaternian\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[39m        (torch.tensor): a batch of quaternion\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 528\u001b[0m     qx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m1\u001b[39;49m]\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m2\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m2\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    529\u001b[0m     qy \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m2\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m2\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    530\u001b[0m     qz \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m2\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m0\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msin(euler[:, \u001b[39m1\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m) \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mcos(euler[:, \u001b[39m2\u001b[39m]\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x270 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create logging folder\n",
    "print(f\"Results will be saved at {work_dir}.\")\n",
    "\n",
    "# Create a trainer for the model\n",
    "model_trainer = models.ModelTrainer(dynamics_model, optim_lr=1e-3, weight_decay=5e-5)\n",
    "\n",
    "# Create visualization objects\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "ax_text = axs[0].text(130, 80, \"\")\n",
    "ax_text.set_color('white')\n",
    "\n",
    "# Main PETS loop\n",
    "all_rewards = [0]\n",
    "total_steps = [0]\n",
    "goal_reached = [0]\n",
    "training_result = []\n",
    "plan_time = 0.0\n",
    "train_time = 0.0\n",
    "\n",
    "record_video = True\n",
    "record_video_frequency = 5\n",
    "\n",
    "for trial in range(num_trials):\n",
    "\n",
    "    # Reset \n",
    "    obs = env.reset()    \n",
    "    agent.reset()\n",
    "    done = False\n",
    "    trial_reward = 0.0\n",
    "    trial_pb_steps = 0.0\n",
    "    steps_trial = 0\n",
    "\n",
    "    # Record video\n",
    "    if record_video and (trial+1) % record_video_frequency == 0:\n",
    "        record_every_n_frames = 3\n",
    "        render_img = env.render(mode=\"rgb_array\")\n",
    "        render_img_size = (render_img.shape[1], render_img.shape[0])\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(\n",
    "            os.path.join(work_dir, \"training_policy_trial_{}.mp4\".format((trial+1))),\n",
    "            fourcc,\n",
    "            24.0,\n",
    "            render_img_size,\n",
    "        )\n",
    "        \n",
    "    update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n",
    "        all_rewards, goal_reached, train_losses[-1], val_scores[-1])\n",
    "    # update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, plan_time, train_time,\n",
    "    #     all_rewards, goal_reached, train_losses[-1], val_scores[-1])\n",
    "    \n",
    "    tcp_pos_workframe, tcp_rpy_workframe, _, _, _ = env.robot.arm.get_current_TCP_pos_vel_workframe()\n",
    "    cur_obj_pos_workframe, cur_obj_orn_workframe = get_states_from_obs(obs)\n",
    "    cur_obj_rpy_workframe = env._pb.getEulerFromQuaternion(cur_obj_orn_workframe)\n",
    "    training_result.append(np.hstack([trial, \n",
    "                                    steps_trial, \n",
    "                                    trial_pb_steps,\n",
    "                                    tcp_pos_workframe, \n",
    "                                    cur_obj_pos_workframe,\n",
    "                                    tcp_rpy_workframe[2],\n",
    "                                    cur_obj_rpy_workframe[2],\n",
    "                                    env.goal_pos_workframe, \n",
    "                                    trial_reward, \n",
    "                                    False,\n",
    "                                    done]))\n",
    "    while not done:\n",
    "\n",
    "        if steps_trial == 0:\n",
    "            # --------------- Model Training -----------------\n",
    "            dynamics_model.update_normalizer(replay_buffer.get_all())  # update normalizer stats            \n",
    "            dataset_train, dataset_val = common_util.get_basic_buffer_iterators(\n",
    "                replay_buffer,\n",
    "                batch_size=cfg.overrides.model_batch_size,\n",
    "                val_ratio=cfg.overrides.validation_ratio,\n",
    "                ensemble_size=ensemble_size,\n",
    "                shuffle_each_epoch=True,\n",
    "                bootstrap_permutes=False,  # build bootstrap dataset using sampling with replacement\n",
    "            )\n",
    "            \n",
    "            start_train_time = time.time()\n",
    "            model_trainer.train(\n",
    "                dataset_train, \n",
    "                dataset_val=dataset_val, \n",
    "                num_epochs=50, \n",
    "                patience=50, \n",
    "                callback=train_callback,\n",
    "                silent=True)\n",
    "            train_time = time.time() - start_train_time\n",
    "\n",
    "            if work_dir is not None:\n",
    "                dynamics_model.save(str(work_dir))\n",
    "                replay_buffer.save(work_dir)\n",
    "\n",
    "        # --- Doing env step using the agent and adding to model dataset ---\n",
    "        start_plan_time = time.time()\n",
    "        next_obs, reward, done, info = common_util.step_env_and_add_to_buffer(\n",
    "            env, obs, agent, {}, replay_buffer)\n",
    "        plan_time = time.time() - start_plan_time\n",
    "\n",
    "        update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n",
    "            all_rewards, goal_reached, train_losses[-1], val_scores[-1])\n",
    "        # update_axes(\n",
    "        #     axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, plan_time, train_time, \n",
    "        #     all_rewards, goal_reached,  train_losses[-1], val_scores[-1])\n",
    "\n",
    "        obs = next_obs\n",
    "        trial_reward += reward\n",
    "        trial_pb_steps += info[\"num_of_pb_steps\"]\n",
    "        steps_trial += 1\n",
    "\n",
    "        # Save data for plotting training performance\n",
    "        tcp_pos_workframe, tcp_rpy_workframe, _, _, _ = env.robot.arm.get_current_TCP_pos_vel_workframe()\n",
    "        cur_obj_pos_workframe, cur_obj_orn_workframe = get_states_from_obs(obs)\n",
    "        cur_obj_rpy_workframe = env._pb.getEulerFromQuaternion(cur_obj_orn_workframe)\n",
    "        training_result.append(np.hstack([trial,\n",
    "                                        steps_trial,\n",
    "                                        trial_pb_steps * env._sim_time_step,\n",
    "                                        tcp_pos_workframe, \n",
    "                                        cur_obj_pos_workframe, \n",
    "                                        tcp_rpy_workframe[2],\n",
    "                                        cur_obj_rpy_workframe[2],\n",
    "                                        env.goal_pos_workframe, \n",
    "                                        trial_reward, \n",
    "                                        info[\"tip_in_contact\"],\n",
    "                                        done]))\n",
    "        \n",
    "        # Record video at every n trials\n",
    "        if record_video and (trial+1) % record_video_frequency == 0 and steps_trial % record_every_n_frames == 0:\n",
    "            render_img = env.render(mode=\"rgb_array\")\n",
    "            render_img = cv2.cvtColor(render_img, cv2.COLOR_BGR2RGB)\n",
    "            out.write(render_img)\n",
    "\n",
    "        if steps_trial == trial_length:\n",
    "            break\n",
    "\n",
    "    all_rewards.append(trial_reward)\n",
    "    total_steps.append(steps_trial + total_steps[-1])\n",
    "\n",
    "    # save goal reached data during training\n",
    "    if env.single_goal_reached:\n",
    "        goal_reached.append(trial_reward)\n",
    "    else:\n",
    "        goal_reached.append(0)\n",
    "\n",
    "    # release video at every n trials\n",
    "    if record_video and (trial+1) % record_video_frequency == 0:\n",
    "        out.release()\n",
    "\n",
    "update_axes_text(axs, trial, steps_trial, plan_time, train_time,\n",
    "    all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)\n",
    "# update_axes(axs, env.render(mode=\"rgb_array\"), ax_text, trial, steps_trial, plan_time, train_time, \n",
    "#     all_rewards, goal_reached, train_losses[-1], val_scores[-1], force_update=True)\n",
    "\n",
    "# Plot results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(total_steps[1:], all_rewards[1:], 'bs-', total_steps[1:], goal_reached[1:], 'rs')\n",
    "ax.set_xlabel(\"Samples\")\n",
    "ax.set_ylabel(\"Trial reward\")\n",
    "fig.savefig(os.path.join(work_dir, \"output.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_push_plots(df, trials, directory):\n",
    "    loss_contact = False\n",
    "    for trial in range(trials):\n",
    "        fig_xy, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.plot(df.query(\"trial==@trial\")[\"tcp_x\"], df.query(\"trial==@trial\")[\"tcp_y\"], \"b-\", label='tcp psosition')\n",
    "        ax.plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_x\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_y\"], \"g+\", markersize=20)\n",
    "        ax.plot(df.query(\"trial==@trial\")[\"contact_x\"], df.query(\"trial==@trial\")[\"contact_y\"], \"r-\", label='contact psosition')\n",
    "        ax.plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_x\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_y\"], \"gx\", markersize=20)\n",
    "        ax.plot(df.query(\"trial==@trial\")[\"goal_x\"].iloc[0], df.query(\"trial==@trial\")[\"goal_y\"].iloc[0], \"x\", markersize=20, markeredgecolor=\"black\", label=\"goal position\")\n",
    "        \n",
    "        for i, rows in df.query(\"trial==@trial\").iterrows():\n",
    "            if i % 10 == 0:\n",
    "                tcp_x, tcp_y, tcp_Rz= rows[\"tcp_x\"], rows[\"tcp_y\"], rows[\"tcp_Rz\"]\n",
    "                tcp_dx, tcp_dy = 0.05 * np.cos(tcp_Rz), 0.05 * np.sin(tcp_Rz)\n",
    "                plt.arrow(tcp_x, tcp_y, tcp_dx, tcp_dy, color='b')\n",
    "                obj_x, obj_y, obj_Rz= rows[\"contact_x\"], rows[\"contact_y\"], rows[\"contact_Rz\"]\n",
    "                obj_dx, obj_dy = 0.05 * np.cos(obj_Rz), 0.05 * np.sin(obj_Rz)\n",
    "                plt.arrow(obj_x, obj_y, obj_dx, obj_dy, color='r')\n",
    "        \n",
    "        ax.set_xlabel(\"x workframe\")\n",
    "        ax.set_ylabel(\"y workframe\")\n",
    "        ax.set_xlim([env.robot.arm.TCP_lims[0, 0], env.robot.arm.TCP_lims[0, 1]])\n",
    "        ax.set_ylim([env.robot.arm.TCP_lims[1, 0], env.robot.arm.TCP_lims[1, 1]])\n",
    "        ax.legend()\n",
    "        fig_xy.savefig(os.path.join(directory, \"workframe_plot_trial_{}.png\".format(trial)))\n",
    "        plt.close(fig_xy)\n",
    "\n",
    "        fig_time_xy, axs = plt.subplots(1, 2, figsize=(14, 3.75), gridspec_kw={\"width_ratios\": [1, 1]})\n",
    "        axs[0].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"tcp_x\"], \"bs\", label='tcp ')\n",
    "        axs[0].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_x\"], \"g+\", markersize=20)\n",
    "        axs[0].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"contact_x\"], \"rs\", label='contact')\n",
    "        axs[0].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_x\"], \"gx\", markersize=20)\n",
    "        axs[0].set_xlabel(\"Time steps (s)\")\n",
    "        axs[0].set_ylabel(\"x axis workframe\")\n",
    "        axs[0].set_ylim([env.robot.arm.TCP_lims[0, 0], env.robot.arm.TCP_lims[0, 1]])\n",
    "        axs[0].legend()\n",
    "        axs[1].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"tcp_y\"], \"bs\", label='tcp')\n",
    "        axs[1].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"tcp_y\"], \"g+\", markersize=20)\n",
    "        axs[1].plot(df.query(\"trial==@trial\")[\"time_steps\"], df.query(\"trial==@trial\")[\"contact_y\"], \"rs\", label='contact')\n",
    "        axs[1].plot(df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"time_steps\"], df.query(\"trial==@trial\").query(\"contact==@loss_contact\")[\"contact_y\"], \"gx\", markersize=20)\n",
    "        axs[1].set_xlabel(\"Time steps (s)\")\n",
    "        axs[1].set_ylabel(\"y axis workframe\")\n",
    "        axs[1].set_ylim([env.robot.arm.TCP_lims[1, 0], env.robot.arm.TCP_lims[1, 1]])\n",
    "        axs[1].legend()\n",
    "        fig_time_xy.savefig(os.path.join(directory, \"time_plot_trial_{}.png\".format(trial)))\n",
    "        plt.close(fig_time_xy)\n",
    "\n",
    "# Save data \n",
    "training_result = np.array(training_result)\n",
    "data_columns = ['trial','trial_steps', 'time_steps', 'tcp_x','tcp_y','tcp_z','contact_x', 'contact_y', 'contact_z', 'tcp_Rz', 'contact_Rz', 'goal_x', 'goal_y', 'goal_z', 'rewards', 'contact', 'dones']\n",
    "df_training = pd.DataFrame(training_result, columns = data_columns)\n",
    "pd.DataFrame(training_result).to_csv(os.path.join(work_dir, \"training_results.csv\"))\n",
    "\n",
    "# Plot the training results\n",
    "training_result_directory = os.path.join(work_dir, \"training_result\")\n",
    "if not os.path.exists(training_result_directory):\n",
    "    os.mkdir(training_result_directory)\n",
    "else:\n",
    "    for filename in os.listdir(training_result_directory):\n",
    "        file_path = os.path.join(training_result_directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "plot_and_save_push_plots(df_training, num_trials, training_result_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training.query(\"trial==14\").query(\"contact==False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main PETS loop\n",
    "num_test_trials = 10\n",
    "all_rewards = []\n",
    "evaluation_result = []\n",
    "goal_reached = []\n",
    "plan_time = 0.0\n",
    "train_time = 0.0\n",
    "save_vid = True\n",
    "render = True\n",
    "\n",
    "if save_vid:\n",
    "    record_every_n_frames = 1\n",
    "    render_img = env.render(mode=\"rgb_array\")\n",
    "    render_img_size = (render_img.shape[1], render_img.shape[0])\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(\n",
    "        os.path.join(work_dir, \"evaluated_policy.mp4\"),\n",
    "        fourcc,\n",
    "        24.0,\n",
    "        render_img_size,\n",
    "    )\n",
    "\n",
    "for trial in range(num_test_trials):\n",
    "    obs = env.reset()    \n",
    "    agent.reset()\n",
    "    \n",
    "    done = False\n",
    "    trial_reward = 0.0\n",
    "    trial_pb_steps = 0.0\n",
    "    steps_trial = 0\n",
    "\n",
    "    tcp_pos_workframe, _, _, _, _ = env.robot.arm.get_current_TCP_pos_vel_workframe()\n",
    "    cur_obj_pos_workframe = get_states_from_obs(obs)\n",
    "    evaluation_result.append(np.hstack([trial, \n",
    "                                        steps_trial, \n",
    "                                        trial_pb_steps,\n",
    "                                        tcp_pos_workframe, \n",
    "                                        cur_obj_pos_workframe, \n",
    "                                        env.goal_pos_workframe, \n",
    "                                        trial_reward, \n",
    "                                        False,\n",
    "                                        done]))\n",
    "    while not done:\n",
    "\n",
    "        # --- Doing env step using the agent and adding to model dataset ---\n",
    "        start_plan_time = time.time()\n",
    "        action = agent.act(obs, **{})\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        plan_time = time.time() - start_plan_time\n",
    "\n",
    "        if render:\n",
    "            render_img = env.render(mode=\"rgb_array\")\n",
    "        else:\n",
    "            render_img = None\n",
    "        \n",
    "        obs = next_obs\n",
    "        trial_reward += reward\n",
    "        trial_pb_steps += info[\"num_of_pb_steps\"]\n",
    "        steps_trial += 1\n",
    "\n",
    "        tcp_pos_workframe, _, _, _, _ = env.robot.arm.get_current_TCP_pos_vel_workframe()\n",
    "        cur_obj_pos_workframe = get_states_from_obs(obs)\n",
    "        evaluation_result.append(np.hstack([trial, \n",
    "                                            steps_trial, \n",
    "                                            trial_pb_steps * env._sim_time_step,\n",
    "                                            tcp_pos_workframe, \n",
    "                                            cur_obj_pos_workframe, \n",
    "                                            env.goal_pos_workframe, \n",
    "                                            trial_reward, \n",
    "                                            info[\"tip_in_contact\"],\n",
    "                                            done]))\n",
    "            \n",
    "         # use record_every_n_frames to reduce size sometimes\n",
    "        if save_vid and steps_trial % record_every_n_frames == 0:\n",
    "\n",
    "            # warning to enable rendering\n",
    "            if render_img is None:\n",
    "                sys.exit('Must be rendering to save video')\n",
    "\n",
    "            render_img = cv2.cvtColor(render_img, cv2.COLOR_BGR2RGB)\n",
    "            out.write(render_img)\n",
    "\n",
    "        if steps_trial == trial_length:\n",
    "            break\n",
    "    \n",
    "    print(\"Terminated at step {} with reward {}, goal reached: {}\".format(steps_trial, trial_reward, env.single_goal_reached))\n",
    "    all_rewards.append(trial_reward)\n",
    "\n",
    "    # save goal reached data during training\n",
    "    if env.single_goal_reached:\n",
    "        goal_reached.append(trial_reward)\n",
    "    else:\n",
    "        goal_reached.append(0)\n",
    "\n",
    "if save_vid:\n",
    "    out.release()\n",
    "\n",
    "print(\"The average reward over {} episodes is {}\".format(num_test_trials, np.mean(all_rewards)))\n",
    "\n",
    "# Save data \n",
    "evaluation_result = np.array(evaluation_result)\n",
    "df_evaluation = pd.DataFrame(evaluation_result, columns = data_columns)\n",
    "pd.DataFrame(evaluation_result).to_csv(os.path.join(work_dir, \"evaluation_results.csv\"))\n",
    "\n",
    "# plot evaluation results\n",
    "evaluation_result_directory = os.path.join(work_dir, \"evaluation_result\")\n",
    "if not os.path.exists(evaluation_result_directory):\n",
    "    os.mkdir(evaluation_result_directory)\n",
    "else:\n",
    "    for filename in os.listdir(evaluation_result_directory):\n",
    "        file_path = os.path.join(evaluation_result_directory, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "\n",
    "plot_and_save_push_plots(df_evaluation, num_test_trials, evaluation_result_directory)\n",
    "\n",
    "# Plot evaluation results\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(all_rewards, 'bs-', goal_reached, 'rs')\n",
    "ax.set_xlabel(\"Trial\")\n",
    "ax.set_ylabel(\"Trial reward\")\n",
    "fig.savefig(os.path.join(work_dir, \"evaluation_output.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check model learning and rollout predictions to see if code is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test optimisation iterations for CEM\n",
    "train_losses = []\n",
    "val_scores = []\n",
    "\n",
    "# Create a 1-D dynamics model for this environment\n",
    "dynamics_model = common_util.create_one_dim_tr_model(cfg, obs_shape, act_shape)\n",
    "\n",
    "# Create a gym-like environment to encapsulate the model\n",
    "model_env = models.ModelEnvPushing(env, dynamics_model, termination_fn=None, reward_fn=None, generator=generator)\n",
    "\n",
    "replay_buffer = common_util.create_replay_buffer(cfg, obs_shape, act_shape, rng=rng)\n",
    "common_util.rollout_agent_trajectories(\n",
    "    env,\n",
    "    buffer_size, # initial exploration steps\n",
    "    planning.RandomAgent(env),\n",
    "    {}, # keyword arguments to pass to agent.act()\n",
    "    replay_buffer=replay_buffer,\n",
    "    trial_length=trial_length\n",
    ")\n",
    "\n",
    "print(\"# samples stored\", replay_buffer.num_stored)\n",
    "\n",
    "# Train model first\n",
    "model_trainer = models.ModelTrainer(dynamics_model, optim_lr= 1e-3, weight_decay=5e-5)\n",
    "dynamics_model.update_normalizer(replay_buffer.get_all())\n",
    "dataset_train, dataset_val = common_util.get_basic_buffer_iterators(\n",
    "    replay_buffer,\n",
    "    batch_size=cfg.overrides.model_batch_size,\n",
    "    val_ratio=cfg.overrides.validation_ratio,\n",
    "    ensemble_size=ensemble_size,\n",
    "    shuffle_each_epoch=True,\n",
    "    bootstrap_permutes=False,  # build bootstrap dataset using sampling with replacement\n",
    ")\n",
    "\n",
    "start_train_time = time.time()\n",
    "model_trainer.train(\n",
    "    dataset_train, \n",
    "    dataset_val=dataset_val, \n",
    "    num_epochs=100, \n",
    "    patience=50, \n",
    "    callback=train_callback,\n",
    "    silent=True)\n",
    "train_time = time.time() - start_train_time\n",
    "\n",
    "print(\"Training time: \", train_time)\n",
    "print(\"Train Loss: {}, Val Loss: {}\".format(train_losses[-1], val_scores[-1]))\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10))\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].set_xlabel(\"Total training epochs\")\n",
    "ax[0].set_ylabel(\"Training loss (avg. NLL)\")\n",
    "ax[0].xaxis.label.set_color('white')\n",
    "ax[0].yaxis.label.set_color('white')\n",
    "ax[0].tick_params(axis='x', colors='white')\n",
    "ax[0].tick_params(axis='y', colors='white')\n",
    "ax[1].plot(val_scores)\n",
    "ax[1].set_xlabel(\"Total training epochs\")\n",
    "ax[1].set_ylabel(\"Validation score (avg. MSE)\")\n",
    "ax[1].xaxis.label.set_color('white')\n",
    "ax[1].yaxis.label.set_color('white')\n",
    "ax[1].tick_params(axis='x', colors='white')\n",
    "ax[1].tick_params(axis='y', colors='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Test model one set of action sequences from buffer to see exploding -------\n",
    "# states still occur\n",
    "\n",
    "planning_horizon = 10\n",
    "\n",
    "# Get action sequence from buffer\n",
    "data = replay_buffer.get_all()\n",
    "action_sequences = data.act[0:planning_horizon,:]\n",
    "action_sequences = np.tile(action_sequences, (5,1,1)).astype(np.float32)\n",
    "action_sequences = torch.from_numpy(action_sequences)\n",
    "# print(action_sequences.shape)\n",
    "\n",
    "# Initialise state and create model input\n",
    "initial_state = data.obs[0]\n",
    "# print(initial_state.shape)\n",
    "initial_obs_batch = np.tile(initial_state, (5,1)).astype(np.float32)\n",
    "# print(initial_obs_batch.shape)\n",
    "model_state = model_env.reset(initial_obs_batch, return_as_np=False)\n",
    "# print(model_state['propagation_indices'])\n",
    "\n",
    "batch_size = initial_obs_batch.shape[0]\n",
    "total_rewards = torch.zeros(batch_size, 1)\n",
    "terminated = torch.zeros(batch_size, 1, dtype=bool)\n",
    "model_env.reset_batch_goals(batch_size)\n",
    "\n",
    "print(data.obs[1][0:3])\n",
    "print(data.next_obs[1][0:3])\n",
    "print(data.act[1])\n",
    "\n",
    "for time_step in range(planning_horizon):\n",
    "    print(torch.mean(model_state[\"obs\"], 0)[0:3])\n",
    "    # print(model_state[\"obs\"].shape)\n",
    "    # print(torch.mean(model_state[\"obs\"]))\n",
    "    action_for_step = action_sequences[:, time_step, :]\n",
    "    # print(action_for_step[0])\n",
    "\n",
    "    # Re-initialise model state from data buffer with every time step (1 step rollouts)\n",
    "    # Comment out to do planning_horizon step rollouts\n",
    "    # initial_state = data.obs[time_step]\n",
    "    # initial_obs_batch = np.tile(initial_state, (5,1)).astype(np.float32)\n",
    "    # initial_obs_batch = torch.from_numpy(initial_obs_batch)\n",
    "    # model_state.update({'obs': initial_obs_batch})\n",
    "    # action_batch = torch.repeat_interleave(\n",
    "    #     action_for_step, 20, dim=0\n",
    "    # )\n",
    "\n",
    "    action_batch = action_for_step\n",
    "    # ---------------- Use model_env.step -----------------\n",
    "    # _, rewards, dones, model_state = model_env.step(\n",
    "    #     action_batch, model_state, sample=True\n",
    "    # )\n",
    "    # rewards[terminated] = 0\n",
    "    # terminated |= dones\n",
    "    # total_rewards += rewards\n",
    "\n",
    "    # -------------- Use one_dim_tr_model sample -------------\n",
    "    # with torch.no_grad():\n",
    "    #     next_observs, _, _, next_model_state, = model_env.dynamics_model.sample(\n",
    "    #         action_batch, model_state, deterministic=False, rng=model_env._rng,\n",
    "    #     )\n",
    "\n",
    "    # -------------- Use model.sample_1d() --------------------\n",
    "    # with torch.no_grad():\n",
    "    #     obs = model_state[\"obs\"]\n",
    "    #     model_in = model_env.dynamics_model._get_model_input(model_state[\"obs\"], action_batch)\n",
    "    #     next_observs, _ = model_env.dynamics_model.model.sample_1d(\n",
    "    #         model_in, model_state, rng=model_env._rng, deterministic=False\n",
    "    #     )\n",
    "    #     next_observs += obs\n",
    "    #     model_state[\"obs\"] = next_observs\n",
    "\n",
    "    # -------------- Use model.forward()-------------------------\n",
    "    with torch.no_grad():\n",
    "        obs = model_state[\"obs\"]\n",
    "        model_in = model_env.dynamics_model._get_model_input(model_state[\"obs\"], action_batch)\n",
    "        means, logvars = model_env.dynamics_model.model.forward(\n",
    "            model_in, rng=model_env._rng, propagation_indices=model_state[\"propagation_indices\"]\n",
    "        )\n",
    "        variances = logvars.exp()\n",
    "        stds = torch.sqrt(variances)\n",
    "        # stds = torch.ones((5,30))\n",
    "        next_observs = torch.normal(means, stds, generator=model_env._rng)\n",
    "        # next_observs = means\n",
    "        # print(torch.mean(means))\n",
    "        # print(torch.mean(logvars))\n",
    "        # print(torch.mean(stds))\n",
    "        if dynamics_model.target_normalizer:\n",
    "            next_observs = dynamics_model.target_normalizer.denormalize(next_observs)\n",
    "\n",
    "        if dynamics_model.target_is_delta:\n",
    "            next_observs += obs\n",
    "        model_state[\"obs\"] = next_observs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation  function\n",
    "def evaluate(env, agent, training_trial_num, work_dir):\n",
    "    \n",
    "    all_rewards = []\n",
    "    evaluation_result = []\n",
    "    goal_reached = []\n",
    "    plan_time = 0.0\n",
    "    train_time = 0.0\n",
    "    save_vid = True\n",
    "    render = True\n",
    "\n",
    "    if save_vid:\n",
    "        record_every_n_frames = 1\n",
    "        render_img = env.render(mode=\"rgb_array\")\n",
    "        render_img_size = (render_img.shape[1], render_img.shape[0])\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(\n",
    "            os.path.join(work_dir, \"evaluated_policy_training_trial_{}.mp4\".format(training_trial_num)),\n",
    "            fourcc,\n",
    "            24.0,\n",
    "            render_img_size,\n",
    "        )\n",
    "\n",
    "    for trial in range(1):\n",
    "        obs = env.reset()    \n",
    "        agent.reset()\n",
    "        \n",
    "        done = False\n",
    "        trial_reward = 0.0\n",
    "        trial_pb_steps = 0.0\n",
    "        steps_trial = 0\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            # --- Doing env step using the agent and adding to model dataset ---\n",
    "            start_plan_time = time.time()\n",
    "            action = agent.act(obs, **{})\n",
    "            next_obs, reward, done, info = env.step(action)\n",
    "            plan_time = time.time() - start_plan_time\n",
    "\n",
    "            if render:\n",
    "                render_img = env.render(mode=\"rgb_array\")\n",
    "            else:\n",
    "                render_img = None\n",
    "            \n",
    "            obs = next_obs\n",
    "            trial_reward += reward\n",
    "            trial_pb_steps += info[\"num_of_pb_steps\"]\n",
    "            steps_trial += 1\n",
    "\n",
    "                \n",
    "            # use record_every_n_frames to reduce size sometimes\n",
    "            if save_vid and steps_trial % record_every_n_frames == 0:\n",
    "\n",
    "                # warning to enable rendering\n",
    "                if render_img is None:\n",
    "                    sys.exit('Must be rendering to save video')\n",
    "\n",
    "                render_img = cv2.cvtColor(render_img, cv2.COLOR_BGR2RGB)\n",
    "                out.write(render_img)\n",
    "\n",
    "            if steps_trial == trial_length:\n",
    "                break\n",
    "        \n",
    "        all_rewards.append(trial_reward)\n",
    "\n",
    "        # save goal reached data during training\n",
    "        if env.single_goal_reached:\n",
    "            goal_reached.append(trial_reward)\n",
    "        else:\n",
    "            goal_reached.append(0)\n",
    "\n",
    "    if save_vid:\n",
    "        out.release()\n",
    "\n",
    "# create a evaluation environment\n",
    "eval_env = gym.make(env_name, **env_kwargs)\n",
    "eval_env.seed(seed)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "288c20f4f30562b85a793c8b692fd9c626a3a2ddfa32fea47b77030b2eed9a18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tactile_gym_mbrl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
